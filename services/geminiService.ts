// FIX: Implemented the missing geminiService to handle API calls.
import { GoogleGenAI, Modality, Type } from "@google/genai";
import type { Tool, ToolParameters, FacialAnalysisResult } from '../types';

// Initialize the Gemini client
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY! });

// Helper function to convert image blob to base64 string without data prefix
const imageBlobToBase64 = (blob: Blob): Promise<string> => {
    return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onloadend = () => {
            const base64data = reader.result as string;
            // The Gemini API expects just the base64 string, without the data URL prefix.
            resolve(base64data.split(',')[1]);
        };
        reader.onerror = reject;
        reader.readAsDataURL(blob);
    });
};


// Function for image transformation
export const transformImage = async (
    image: Blob,
    tool: Tool,
    params: ToolParameters
): Promise<string> => { // Returns base64 string of the new image
    
    const base64Image = await imageBlobToBase64(image);

    let textPrompt = `Apply the ${tool.name} transformation.`;

    switch(tool.id) {
        case 'hairstyle':
            textPrompt = `Change the hairstyle to "${params.style}".`;
            if (params.color) {
                textPrompt += ` The hair color should be ${params.color}.`;
            }
            break;
        case 'hair-color':
            textPrompt = `Change the hair color to ${params.color}.`;
            break;
        case 'eye-color':
            textPrompt = `Change the eye color to ${params.eyeColor}.`;
            break;
        case 'skin-color':
            textPrompt = `Change the skin tone to ${params.skinTone}.`;
            break;
        case 'age':
            textPrompt = `Make the person in the image look ${params.age} years old.`;
            break;
        case 'smile':
            textPrompt = `Add a natural smile to the person's face with an intensity of ${params.intensity}%.`;
            break;
        case 'fat':
            textPrompt = `Make the person in the image look heavier by an intensity of ${params.intensity}%.`;
            break;
        case 'bald':
            textPrompt = `Make the person in the image look bald with an intensity of ${params.intensity}%.`;
            break;
        case 'beard':
            textPrompt = `Apply a "${params.beardStyle}" beard style.`;
            break;
        case 'halloween':
             textPrompt = `Apply a halloween filter. The style should focus on "${params.halloweenStyle}".`;
            break;
        default:
            throw new Error(`Unsupported tool for image transformation: ${tool.id}`);
    }

    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: {
        parts: [
          {
            inlineData: {
              data: base64Image,
              mimeType: image.type,
            },
          },
          {
            text: textPrompt,
          },
        ],
      },
      config: {
          responseModalities: [Modality.IMAGE],
      },
    });

    for (const part of response.candidates[0].content.parts) {
      if (part.inlineData) {
        return part.inlineData.data;
      }
    }
    
    throw new Error('No image was generated by the API.');
};

// Function for facial analysis
export const analyzeFace = async (image: Blob): Promise<FacialAnalysisResult> => {
    const base64Image = await imageBlobToBase64(image);

    const analysisSchema = {
        type: Type.OBJECT,
        properties: {
            faceShape: { type: Type.STRING, description: 'The detected shape of the face (e.g., Oval, Round, Square).' },
            symmetryScore: { type: Type.NUMBER, description: 'A score from 0 to 100 indicating facial symmetry.' },
            youthfulnessScore: { type: Type.NUMBER, description: 'A score from 0 to 100 indicating youthfulness.' },
            skinClarity: { type: Type.NUMBER, description: 'A score from 0 to 100 for skin clarity (absence of blemishes).' },
            overallAnalysis: { type: Type.STRING, description: 'A brief, 2-3 sentence overall analysis of the facial features.' },
            eyeShape: { type: Type.STRING, description: 'The detected shape of the eyes (e.g., Almond, Round).' },
            jawlineDefinitionScore: { type: Type.NUMBER, description: 'A score from 0 to 100 for jawline definition.' },
            cheekboneProminenceScore: { type: Type.NUMBER, description: 'A score from 0 to 100 for cheekbone prominence.' },
            lipFullnessScore: { type: Type.NUMBER, description: 'A score from 0 to 100 for lip fullness.' },
            skinEvennessScore: { type: Type.NUMBER, description: 'A score from 0 to 100 for skin tone evenness.' },
            goldenRatioScore: { type: Type.NUMBER, description: 'A score from 0 to 100 indicating how closely the facial proportions match the golden ratio.' },
            emotionalExpression: { type: Type.STRING, description: 'The detected primary emotional expression (e.g., Neutral, Happy, Surprised).' },
            perceivedAge: { type: Type.INTEGER, description: 'The estimated age of the person in the image.' },
        },
        required: [
            'faceShape', 'symmetryScore', 'youthfulnessScore', 'skinClarity', 'overallAnalysis',
            'eyeShape', 'jawlineDefinitionScore', 'cheekboneProminenceScore', 'lipFullnessScore',
            'skinEvennessScore', 'goldenRatioScore', 'emotionalExpression', 'perceivedAge'
        ]
    };

    const response = await ai.models.generateContent({
        model: 'gemini-2.5-pro',
        contents: {
            parts: [
                {
                    inlineData: {
                        mimeType: image.type,
                        data: base64Image,
                    },
                },
                { text: 'Analyze the facial features in this image and provide a detailed report according to the provided JSON schema.' },
            ],
        },
        config: {
            responseMimeType: "application/json",
            responseSchema: analysisSchema,
        },
    });

    const jsonStr = response.text.trim();
    return JSON.parse(jsonStr) as FacialAnalysisResult;
};
